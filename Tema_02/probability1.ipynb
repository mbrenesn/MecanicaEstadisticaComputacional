{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eventos y Espacio de Muestras\n",
    "\n",
    "La idea principal corresponde a considerar un experimento **cuyo resultado no se conoce por adelantado**. \n",
    "\n",
    "Sea $S$ el espacio de muestras del experimento que denota el **conjunto de todos los posibles resultados**.\n",
    "\n",
    "**Ejemplo 1**:\n",
    "- Una carrera de siete caballos con números del 1 al 7. Entonces:\n",
    "    - $S =$ {cualquier order de $(1, 2, 3, 4, 5, 6, 7)$ }\n",
    "    - En este caso, e.g., (3, 4, 1, 7, 6, 5, 2) implica el caballo 3 llegó primero, el 4 de segundo, ...\n",
    "\n",
    "Un subconjunto $A$ del espacio de muestras se conoce como un **evento**, i.e., un **evento** es un conjunto de posibles resultados del experimento. \n",
    "- Si el resultado del experimento está contenido en el conjunto $A$, decimos que $A$ **ha ocurrido**.\n",
    "<div style=\"text-align: right;\">\n",
    "$\\blacksquare$\n",
    "</div>\n",
    "\n",
    "**Ejemplo 2**:\n",
    "- En el Ejemplo 1, si\n",
    "    - $A =$ {todos los resultados de $S$ que comienzan con 5}\n",
    "    - En este caso, $A$ corresponde al evento en el cual el caballo 5 llega en primera posición\n",
    "<div style=\"text-align: right;\">\n",
    "$\\blacksquare$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para cualesquiera eventos $A$ y $B$, definimos $A \\cup B$ como la **unión** de $A$ y $B$ que consiste en todos los resultados contenidos en $A$, en $B$ o en ambos $A$ y $B$.\n",
    "- Para cualesquiera eventos $A$ y $B$, definimos $AB$ como la **intersección** de $A$ y $B$ que consiste en todos los resultados contenidos en ambos $A$ y $B$.\n",
    "    - $A \\cup B$ ocurre si cualquiera $A$ o $B$ ocurren\n",
    "    - $AB$ ocurre solo si ambos $A$ y $B$ ocurren\n",
    "\n",
    "**Definición: Unión e intersección**\n",
    "- La unión de eventos $A_i\\; \\forall i = 1, \\cdots, n$; se denota como $\\cup_{i=1}^{n} A_i$\n",
    "- La intersección de eventos $A_i\\; \\forall i = 1, \\cdots, n$; se denota como $A_1, \\cdots, A_n$\n",
    "- Definimos como $A^c$ al complemento de $A$; i.e., el subconjunto de $S$ que contiene todos los resultados del experimento no contenidos en $A$. $A^c$ ocurre si $A$ no ocurre.\n",
    "\n",
    "Dado que $S$ contiene todos los posibles resultados, $S^c$ no contiene ningún evento; i.e., $S^c = \\emptyset$.\n",
    "- Si $AB = \\emptyset$, esto implica que $A$ y $B$ no puede ocurrir al mismo tiempo. A estos eventos les llamamos **eventos mutuamente excluyentes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axiomas de Probabilidad\n",
    "\n",
    "Supongamos que para cada evento $A$ de un espacio de muestras $S$ existe un número $P(A)$, llamado la probabilidad del evento $A$, que sigue los siguientes tres axiomas\n",
    "\n",
    "- $0 \\leq P(A) \\leq 1$\n",
    "    - La probabilidad es un número entre 0 y 1.\n",
    "- P(S) = 1\n",
    "    - La probabilidad de que cualquier posible evento ocurra es 1.\n",
    "- Para cualquier secuencia de eventos mutuamente excluyentes $A_1, A_2, \\cdots, A_n$:\n",
    "    - $P(\\cup_i^n A_i) = \\sum_{i=1}^{n} P(A_i),\\; \\forall n = 1, 2, \\cdots, \\infty$\n",
    "        - Para cualquier conjunto de eventos mutuamente excluyentes, la probabilidad de que al menos uno de esos eventos ocurra es la suma de las respectivas probabilidades de cada subconjunto $A_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto podemos probar otros resultados. E.g., dado que $A$ y $A^c$ son mutuamente excluyentes y $A \\cup A^c = S$, se cumple que\n",
    "$$\n",
    "1 = P(S) = P(A \\cup A^c) = P(A) + P(A^c) \\implies P(A^c) = 1 - P(A)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad Condicional e Independencia\n",
    "\n",
    "Estudiemos estos conceptos con un ejemplo. Suponga que realizamos un experimento en el cual realizamos dos tiros de una moneda, donde el resultado de cada tiro es *escudo* (H) o *corona* (T). Tenemos\n",
    "$$\n",
    "S = \\{ (H,H), (H,T), (T,H), (T,T) \\}\n",
    "$$\n",
    "Supongamos que $P(X) = 1 / 4$, donde $X = (H,H), (H,T), (T,H), (T,T)$. \n",
    "\n",
    "Considere la siguiente pregunta:\n",
    "- Realizamos el primer tiro de la moneda y el resultado es (H). Dada esta información, ¿cual es la probabilidad de que el resultado del experimento sea (H, H)?\n",
    "\n",
    "Razonamos de la siguiente forma:\n",
    "- El primer tiro es (H), entonces los resultados del experimento deben ser (H, H) o (H, T).\n",
    "- Originalmente, (H, H) y (H, T) tienen la misma probabilidad de ocurrir.\n",
    "- Esto es, dado que (H) ocurrió, la probabilidad **condicional** de que (H, H) o (H, T) ocurra es $1 / 2$.\n",
    "- Adicionalmente, ambos eventos (H, H) y (H, T) tenían la misma probabilidad de ocurrir antes de saber que el primer tiro es (H).\n",
    "- La probabilidad **condicional** de que (T, H) y (T, T) ocurran es **cero**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denotamos con $A$ y $B$ a los eventos (H, H) y al evento del primer tiro (H), respectivamente. La probabilidad que discutimos anteriormente se conoce como **la probabilidad condicional de $A$ dado $B$** y se denota con\n",
    "$$\n",
    "P(A | B).\n",
    "$$\n",
    "Podemos expresar $P(A | B)$ con base en otras cantidades probabilísticas. Si el evento $B$ ocurre, para que ocurra $A$ es necesario que el resultado del experimento sea un elemento de $AB$. Dado que $B$ ocurrió, se tiene que $B$ es **nuestro nuevo espacio de muestras**, lo cual implica que la probabilidad de que $AB$ ocurra es **la probabilidad de $AB$ relativa con respecto a la probabilidad de $B$**.\n",
    "- Probabilidad condicional:\n",
    "$$\n",
    "P(A | B) = \\frac{P(AB)}{P(B)}. \\label{eq:condprob}\\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinar la probabilidad de algún evento $A$ se simplifica usualmente si consideramos un segundo evento $B$ y posteriormente determinar la probabilidad condicional de $A$ dado que $B$ ocurrió y la probabilidad de $A$ dado que $B$ no ocurrió. Note que:\n",
    "$$\n",
    "A = AB \\cup AB^c.\n",
    "$$\n",
    "Dado que $AB$ y $AB^c$ son mutuamente excluyentes:\n",
    "\\begin{align}\n",
    "P(A) &= P(AB) + P(AB^c) \\\\\n",
    "&= P(A|B)P(B) + P(A|B^c)P(B^c).\n",
    "\\end{align}\n",
    "De esta forma, podemos calcular la probabilidad de $A$ condicionada en si $B$ ocurre o no ocurre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, la probabilidad condicional $P(A|B) \\neq P(A)$. Es decir, en general, conocer si $B$ ocurre cambia la probabilidad de que $A$ ocurra. Sin embargo, en el caso especial en el cual $P(A | B) = P(A)$, **decimos que $A$ y $B$ son independientes**. De la Ecuación \\ref{eq:condprob}, vemos que $A$ y $B$ son independientes si\n",
    "$$\n",
    "P(A | B) = P(A) P(B)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Aleatoria\n",
    "\n",
    "- Usamos **variables aleatorias** para representar el valor de alguna cantidad numérica que toma un valor cuando realizamos algún experimento.\n",
    "\n",
    "**Definición: Función de la distribución acumulativa discreta (CDF, cumulative distribution function)**\n",
    "\n",
    "La función de la distribución acumulativa $F$ de una variable aleatoria $X$ se define por un número $x \\in \\mathbb{R}$ tal que\n",
    "$$\n",
    "F(x) = P\\{ X \\leq x \\}.\n",
    "$$\n",
    "Una variable aleatoria que un número finito (o, a lo sumo, un número contable) de posibles valores se conoce como una **variable aleatoria discreta**. \n",
    "\n",
    "**Definición: Función de la masa de probabilidad (PMF, probability mass function)**\n",
    "\n",
    "Para una variable aleatoria discreta $X$, definimos para la función de la masa de probabilidad $p(x)$ como\n",
    "$$\n",
    "p(x) = P\\{ X = x \\}.\n",
    "$$\n",
    "Dado que $X$ es una variable aleatoria discreta que puede tomar los valores $x_1, x_2, \\cdots, x_n$, entonces\n",
    "$$\n",
    "\\sum_{i=1}^{n} p(x_i) = 1.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definición: Función de la densidad de probabilidad (PDF, probability density function)**\n",
    "\n",
    "En algunas ocasiones, debemos considerar experimentos en los cuales la variable aleatoria no toma un valor discreto, si no uno **continuo**. Decimos que $X$ es una **variable aleatoria continua** si existe una función no negativa $f(x)$ definida para todos los valores $x \\in \\mathbb{R}$ que tiene la propiedad de que para cualquier conjunto $C$ de números reales tal que\n",
    "$$\n",
    "P\\{ X \\in C \\} = \\int_C {\\textrm{d}x\\;} f(x).\n",
    "$$\n",
    "La función $f$ se conoce como la función de la densidad de probabilidad de la variable $X$.\n",
    "\n",
    "**Definición: Función de la distribución acumulativa continua (CDF, cumulative distribution function)**\n",
    "\n",
    "La relación entre la función de la disctribución acumulativa y la función de la densidad de probabilidad está dada por\n",
    "$$\n",
    "F(a) = P\\{ X \\in (-\\infty, a) \\} = \\int_{-\\infty}^{a} {\\textrm{d}x\\;} f(x).\n",
    "$$\n",
    "Note que\n",
    "$$\n",
    "\\frac{{\\textrm{d}}}{{\\textrm{d}a}} F(a) = f(a),\n",
    "$$\n",
    "lo cual implica que la PDF es la primera derivada de la CDF con respecto a la variable $a$ que denota el intervalo de posibles valores de la variable aleatoria continua $X$ en cuestión.\n",
    "\n",
    "Veamos:\n",
    "$$\n",
    "P\\Big\\{ a - \\frac{\\varepsilon}{2} \\leq X \\leq a + \\frac{\\varepsilon}{2} \\Big\\} = \\int_{a - \\varepsilon/2}^{a + \\varepsilon/2} {\\textrm{d}x\\;} f(x) \\approx \\varepsilon f(a),\n",
    "$$\n",
    "cuando $\\varepsilon << 1$. Esto implica que la probabilidad de que $X$ esté contenida en un intervalo de tamaño $\\varepsilon$ alrededor del valor $a$ es $\\varepsilon f(a)$.\n",
    "De forma intuitiva, entonces, $f(a)$ es una medida de que tan probable es que una variable aleatoria se encuentre cerca de $a$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariables aleatorias\n",
    "\n",
    "En muchos casos, deseamos expresar múltiples variables aleatorias y su relación de las unas con las otras. \n",
    "\n",
    "**Definición: Función de la distribución acumulativa discreta conjunta (joint CDF, joint cumulative distribution function)**\n",
    "\n",
    "La CDF conjunta de dos variables $X$ y $Y$ es\n",
    "$$\n",
    "F(x, y) = P\\{ X \\leq x, Y \\leq y \\},\n",
    "$$\n",
    "donde $F(x, y)$ representa la probabilidad de que, **simulatáneamente**, $X$ sea menos que $x$ y $Y$ menos que $y$.\n",
    "\n",
    "**Definición: Función de la masa de probabilidad conjunta (joint PMF, joint probability mass function)**\n",
    "\n",
    "La PMF conjunta de dos variables $X$ y $Y$ se define como\n",
    "$$\n",
    "p(x, y) = P\\{ X = x, Y = y \\}\n",
    "$$\n",
    "\n",
    "**Definición: Función de la densidad de probabilidad conjunta (joint PDF, joint probability density function)**\n",
    "\n",
    "La PDF conjunta de dos variables $X$ y $Y$ se define como $f(x, y)$ si para dos conjuntos de números reales $C$ y $D$\n",
    "$$\n",
    "P\\{ X \\in C, Y \\in D \\} = \\int_{x \\in C} \\int_{y \\in D} {\\textrm{d}x} {\\textrm{d}y\\;} f(x, y)\n",
    "$$\n",
    "La CDF conjunta sigue la misma regla que para el caso de una variable.\n",
    "\n",
    "#### Independencia\n",
    "\n",
    "Decimos que dos variables $X$ y $Y$ son independientes si para dos conjuntos de números reales $C$ y $D$ se cumple que\n",
    "$$\n",
    "P\\{ X \\in C, Y \\in D \\} = P\\{ X \\in C\\} P\\{ Y \\in D \\}.\n",
    "$$\n",
    "esto es, $X$ y $Y$ son independientes si todos los eventos $A = \\{X \\in C\\}$ y $B = \\{Y \\in D\\}$ son independientes.\n",
    "*Grosso modo*, $X$ y $Y$ son independientes si conocer el valor de una variable no afecta la PDF de la otra.\n",
    "\n",
    "Usando los axiomas de probabilidad, se puede probar que dos variables aleatorias discretas son independientes si y solo si\n",
    "$$\n",
    "P\\{ X = x, Y = y \\} = P\\{ X = x\\} P\\{ Y = y \\}.\n",
    "$$\n",
    "Similarmente, si $X$ y $Y$ son dos variables aleatorias con PDF conjunta $f(x, y)$, entonces son independientes si y solo si\n",
    "$$\n",
    "f(x, y) = f_X(x)f_Y(y),\n",
    "$$\n",
    "donde $f_X(x)$ y $f_Y(y)$ son las PDFs de $X$ y $Y$, respectivamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectación\n",
    "\n",
    "Uno de los conceptos más importantes en la teoría de la probabilidad es la expectación, o valor de expectación, de una variable aleatoria. \n",
    "\n",
    "#### Valor de expectación de una variable aleatoria discreta\n",
    "\n",
    "Para una variable discreta $X$ que puede tomar los posibles valores $x_1, x_2, \\cdots$; el **valor de expectación**, también conocido el **valor promedio** de $X$ se denota por $E[X]$ y se define por\n",
    "$$\n",
    "E[X] = \\sum_{i} x_i P\\{X = x_i\\}. \n",
    "$$\n",
    "El valor de expectación es el promedio de los valores que $X$ puede tomar, pesado por la probabilidad de que esos valores de $X$ ocurran.\n",
    "\n",
    "**Ejemplo 3**\n",
    "\n",
    "Si la PMF de una variable $X$ que puede tomar los valores $X = 0, 1$ está dada por\n",
    "$$\n",
    "p(0) = p(1) = \\frac{1}{2},\n",
    "$$\n",
    "entonces\n",
    "$$\n",
    "E[X] = 0 \\Big( \\frac{1}{2} \\Big) +  1 \\Big( \\frac{1}{2} \\Big) = \\frac{1}{2}.\n",
    "$$\n",
    "esto es, el valor de expectación es el promedio de los posibles valores. Sin embargo, si \n",
    "$$\n",
    "p(0) = \\frac{1}{3}\\;, p(1) = \\frac{2}{3};\n",
    "$$\n",
    "entonces,\n",
    "$$\n",
    "E[X] = 0 \\Big( \\frac{1}{3} \\Big) +  1 \\Big( \\frac{2}{3} \\Big) = \\frac{2}{3}.\n",
    "$$\n",
    "<div style=\"text-align: right;\">\n",
    "$\\blacksquare$\n",
    "</div>\n",
    "\n",
    "**Ejemplo 4**\n",
    "\n",
    "Si $I$ es una variable aleatoria indicadora del evento $A$, i.e., si\n",
    "$$\n",
    "I = \\begin{cases} 1\\; {\\textrm{si}}\\; A\\; {\\textrm{ocurre}} \\\\ 0\\; {\\textrm{si}}\\; A\\; {\\textrm{no ocurre}} \\end{cases}\n",
    "$$\n",
    "entonces\n",
    "$$\n",
    "E[I] = 1 \\cdot P(A) + 0 \\cdot P(A^c) = P(A).\n",
    "$$\n",
    "Se sigue que la expectación de un indicador de un evento $A$ corresponde a la probabilidad de que $A$ ocurra.\n",
    "<div style=\"text-align: right;\">\n",
    "$\\blacksquare$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valor de expectación de una variable aleatoria continua\n",
    "\n",
    "En el caso cuando requerimos de una PDF, de forma análoga al caso discreto, definimos\n",
    "$$\n",
    "E[X] = \\int_{-\\infty}^{+\\infty} xf(x) {\\textrm{d}x}.\n",
    "$$\n",
    "\n",
    "**Ejemplo 5**\n",
    "\n",
    "Si la PDF de una variable $X$ está dada por \n",
    "$$\n",
    "f(x) = \\begin{cases} 3x^2\\; {\\textrm{si}}\\; 0 < x < 1 \\\\ 0\\; {\\textrm{de otra forma}} \\end{cases}\n",
    "$$\n",
    "entonces\n",
    "$$\n",
    "E[X] = \\int_0^1 3x^3 {\\textrm{d}x} = \\frac{3}{4}\n",
    "$$\n",
    "<div style=\"text-align: right;\">\n",
    "$\\blacksquare$\n",
    "</div>\n",
    "\n",
    "- Cuanto deseamos determinar el valor de expectación de una variable aleatoria $g(X)$ donde $g$ es alguna función dada, parece intuitivo que el valor de expectación $E[g(X)]$ sea el promedio pesado de todos los valores $g(x)$ que puede tomar la función $g(X)$. Esto se debe a que cuando $X$ toma un valor $x$, $g(X)$ toma un valor $g(x)$. Básicamente, asociamos la probabilidad de que g(X) ocurra con la probabilidad de que $X = x$ (o, con PDF para el caso continuo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proposición**\n",
    "\n",
    "Si $X$ es una variable aleatoria discreta con PMF $p(x)$, entonces\n",
    "$$\n",
    "E[g(X)] = \\sum_x g(x)p(x).\n",
    "$$\n",
    "En el caso continuo, si $X$ es una variable aleatoria continua con PDF $f(x)$, entonces\n",
    "$$\n",
    "E[g(X)] = \\int_{-\\infty}^{\\infty} {\\textrm{d}x} g(x)f(x).\n",
    "$$\n",
    "\n",
    "**Corolario**\n",
    "\n",
    "Si $a$ y $b$ son constantes $a, b \\in \\mathbb{R}$, entonces\n",
    "$$\n",
    "E[aX + b] = aE[X] + b.\n",
    "$$\n",
    "La prueba se puede hacer con el siguiente razonamiento. En el caso de una variable aleatoria discreta\n",
    "\\begin{align}\n",
    "E[aX + b] &= \\sum_x (ax + b)p(x) \\\\\n",
    "&= a\\sum_x xp(x) + b \\sum_x p(x) \\\\\n",
    "&= aE[X] + b\n",
    "\\end{align}\n",
    "El resultado se establece de la misma forma para el caso continuo.\n",
    "<div style=\"text-align: right;\">\n",
    "$\\blacksquare$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linealidad \n",
    "\n",
    "El valor de expectación es una operación lineal. Se puede probar sencillamente que para dos variables aleatorias $X_1$ y $X_2$\n",
    "$$\n",
    "E[X_1 + X_2] = E[X_1] + E[X_2],\n",
    "$$\n",
    "lo cual se generaliza a\n",
    "$$\n",
    "E\\Bigg[ \\sum_{i=1}^{n} X_i \\Bigg] = \\sum_{i=1}^{n} E[X_i]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varianza\n",
    "\n",
    "El valor de expectación de una variable $X$ se entiende como el promedio de $X$ pesado por la probabilidad de los posibles valores de $X$. Dado esto, dicho valor no entrega información acerca de la *variación* de estos valores. Una forma de medir esta variación corresponde a realizar un promedio de la diferencia al cuadrado entre $X$ y $E[X]$. \n",
    "\n",
    "#### Varianza de una variable aleatoria\n",
    "\n",
    "Para una variable aleatoria $X$ con promedio $\\mu = E[X]$, la varianza denotada por ${\\textrm{var}[X]}$ se define por\n",
    "$$\n",
    "{\\textrm{var}[X]} = E[(X - \\mu)^2].\n",
    "$$\n",
    "Una forma alternativa corresponde a expresar\n",
    "\\begin{align}\n",
    "{\\textrm{var}[X]} &= E[(X - \\mu)^2] \\\\\n",
    "&= E[X^2 - 2\\mu X + \\mu^2] \\\\\n",
    "&= E[X^2] - E[2\\mu X] + E[\\mu^2] \\\\\n",
    "&= E[X^2] - 2\\mu E[X] + \\mu^2 \\\\\n",
    "&= E[X^2] - \\mu^2.\n",
    "\\end{align}\n",
    "Entonces\n",
    "$$\n",
    "{\\textrm{var}[X]} = E[X^2] - (E[X])^2.\n",
    "$$\n",
    "Se puede probar que para dos constantes $a, b \\in \\mathbb{R}$, se cumple que\n",
    "$$\n",
    "{\\textrm{var}[aX + b]} = a^2 {\\textrm{var}[X]}.\n",
    "$$\n",
    "<div style=\"text-align: right;\">\n",
    "$\\blacksquare$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mientras que la expectación de la suma de dos variables aleatorias es la suma de los valores de expectación, lo mismo no es, en general, el caso para la varianza. \n",
    "Sin embargo, para el caso de variables **independientes**, la propiedad de linealidad si se cumple. Esto nos lleva a definir el concepto de covarianza.\n",
    "\n",
    "**Definición: Covarianza**\n",
    "\n",
    "La covarianza entre dos variable aleatorias $X$ y $Y$, denotada como cov$(X, Y)$, se define como\n",
    "$$\n",
    "{\\textrm{cov}(X, Y)} = E[(X - \\mu_x) (Y - \\mu_y)],\n",
    "$$\n",
    "donde $E[X] = \\mu_x$ y $E[Y] = \\mu_y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la linealidad del valor de expectación, podemos expresar\n",
    "\\begin{align}\n",
    "{\\textrm{cov}(X, Y)} &= E[(XY - \\mu_x Y - X\\mu_y + \\mu_x \\mu_y] \\\\\n",
    "&= E[XY] - \\mu_x E[Y] - \\mu_y E[X] + \\mu_x \\mu_y \\\\\n",
    "&= E[XY] - E[X] E[Y].\n",
    "\\end{align}\n",
    "Este resultado es importante porque nos deja encontrar una expresión para ${\\textrm{var}[X + Y]}$. Veamos, dado que\n",
    "$$\n",
    "E[X + Y] = E[X] + E[Y] = \\mu_x + \\mu_y,\n",
    "$$\n",
    "entonces\n",
    "\\begin{align}\n",
    "{\\textrm{var}[X + Y]} &= E[(X + Y -\\mu_x - \\mu_y)^2] \\\\\n",
    "&= E[(X - \\mu_x)^2 + (Y - \\mu_y)^2 + 2(X - \\mu_x)(Y - \\mu_y)] \\\\\n",
    "&= E[(X - \\mu_x)^2] + E[(Y - \\mu_y)^2] + 2E[(X - \\mu_x)(Y - \\mu_y)] \\\\\n",
    "&= {\\textrm{var}}[X] + {\\textrm{var}}[Y] + 2{\\textrm{cov}}(X, Y)\n",
    "\\end{align}\n",
    "<div style=\"text-align: right;\">\n",
    "$\\blacksquare$\n",
    "</div>\n",
    "\n",
    "**Proposición**\n",
    "\n",
    "Si $X$ y $Y$ son dos variables aleatorias independientes, entonces\n",
    "$$\n",
    "{\\textrm{cov}}(X, Y) = 0.\n",
    "$$\n",
    "Para la prueba, debemos demostrar que\n",
    "\\begin{align}\n",
    "E[XY] &= \\sum_j \\sum_i x_i y_j P\\{ X = x_i, Y = y_j \\} \\\\\n",
    "&= \\sum_j \\sum_i x_i y_j P\\{ X = x_i \\} P\\{ Y = y_j \\}\\;({\\textrm{por independencia}}) \\\\\n",
    "&= \\sum_j y_j P\\{ Y = y_j \\} \\sum_i x_i P\\{ X = x_i \\} \\\\\n",
    "&= E[Y] E[X]\n",
    "\\end{align}\n",
    "Lo cual implica que cov$(X, Y) = 0$. La prueba es similar para el caso continuo usando el mismo argumento.\n",
    "<div style=\"text-align: right;\">\n",
    "$\\blacksquare$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlaciones\n",
    "\n",
    "Las correlaciones entre dos variables aleatorias $X$ y $Y$ se denota mediante corr$(X, Y)$ y se define por\n",
    "$$\n",
    "{\\textrm{corr}}(X, Y) = \\frac{{\\textrm{cov}}(X, Y)}{\\sqrt{{\\textrm{var}[X]}{\\textrm{var}[Y]}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios análisis\n",
    "\n",
    "1. La variable aleatoria $X$ toma los valores 1, 2, 3, 4 con probabilidad\n",
    "$$\n",
    "P\\{ X  = i \\} = ic,\\; i = 1,2,3,4\n",
    "$$\n",
    "para algún valor $c$. Encuentre $P\\{2 \\leq X \\leq 3\\}$\n",
    "2. Si $X$ y $Y$ poseen una PDF conjunta dada por\n",
    "$$\n",
    "f(x,y) = 2e^{-(x + 2y)},\\; 0 < x < +\\infty, 0 < y < +\\infty,\n",
    "$$\n",
    "encuentre $P\\{ X < Y \\}$\n",
    "3. Encuentre el valor de expectación del Ejercicio 1.\n",
    "4. Un dado \"limpio\" tiene la misma probabilidad de que cualquier cara caiga. Determine la varianza del número que caerá.\n",
    "5. Pruebe que var$[aX +b]$ = $a^2$var$[X]$.\n",
    "\n",
    "## Ejercicio computacional\n",
    "\n",
    "En el ensamble canónico, la probabilidad de que un sistema se encuentre en un estado $i$ con energía $E_i$ a la temperatura $T$ está dada por la distribución de Boltzmann, la cual tiene una PDF dada por\n",
    "$$\n",
    "P(E_i) = \\frac{e^{-\\beta E_i}}{Z},\\; \\beta = \\frac{1}{T},\\; Z = \\sum_i e^{-\\beta E_i}.\n",
    "$$\n",
    "El valor de expectación $\\langle E \\rangle$ se refiere al valor más probable de la energía total a la temperatura $T$ y la varianza $\\sigma^2_E = \\langle E^2 \\rangle - \\langle E \\rangle^2 = T^2 C_V$ se refiere a la capacidad calórica. \n",
    "- Para un sistema con $E_n = n\\epsilon, n = 0, 1, 2, \\cdots, N_{\\textrm{max}}$, escriba una implementación en `Python` para\n",
    "    1. Calcular la función de partición $Z$\n",
    "    2. Calcular la distribución $P(E_n)$ como función de la temperatura\n",
    "    3. Calcular el valor de expectación $\\langle E \\rangle$ con respecto a la temperatura\n",
    "    4. Calcular la varianza de energía con respecto a la temperatura"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
