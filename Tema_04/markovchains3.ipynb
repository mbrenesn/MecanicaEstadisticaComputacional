{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muestreo de Gibbs y aplicaciones de cadenas de Markov en física estadística\n",
    "\n",
    "En nuestra lección anterior:\n",
    "- Establecimos el teorema ergódico para cadenas Markov.\n",
    "  * El teorema establece que en el límite de tiempo largo, el promedio temporal evaluado a lo largo de una trayectoria de una de cadena de Markov converge el promedio de ensamble bajo la distribución estacionaria.\n",
    "  * El teorema es increíblemente útil en ambos sentidos, i.e., cuando deseo conocer el promedio temporal utilizo el promedio de ensamble y vicerversa, dependiendo cuál cantidad sea accesible para describir el problema.\n",
    "  * Planteamos que para que el teorema ergódico se cumpla, la cadena de Markov debe ser aperiódica e irreducible.\n",
    "- La descomposición de la matriz de transición $\\mathbf{Q}$ en su base de autovectores nos deja expresar cualquier distribución como una combinación lineal de autovectores, la cual nos lleva a la conclusión de que el estado estacionario corresponde al autovector con autovalor 1, de acuerdo con el teorema de Perron-Frobenius.\n",
    "- El método de Metropolis-Hastings nos entrega un algoritmo para obtener **distribuciones de equilibrio cuando el espacio de configuración de cierto sistema no puede ser muestreado de forma tratable**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestreo de Gibss\n",
    "\n",
    "El muestreo de Gibbs corresponde a la versión **más utilizada del método de Metropolis-Hastings (MH)**.\n",
    "- La conexión entre el método MH y el muestreo de Gibbs es sutil.\n",
    "  * Ambos corresponden a métodos de Monte Carlo tipo cadenas de Markov.\n",
    "  * Ambos corresponden a métodos para obtener distribuciones estacionarias objetivo $\\vec{P}^*$.\n",
    "  * Sin embargo, difieren en la forma en que **proponen y aceptan nuevos estados de forma iterativa**.\n",
    "\n",
    "Sea $\\mathbf{X} = (X_1, \\cdots, X_n)$ un vector aleatorio con PMF $p(\\mathbf{x})$ que debe ser especificada módulo una constante multiplicativa arbitraria. \n",
    "- En nuestras lecciones anteriores, habíamos llamado $\\vec{P}(t)$ a la PMF de la distribución al tiempo $t$. La notación anterior será más útil para la discusión del muestreo de Gibbs. $p(\\mathbf{x})$ corresponde a $\\vec{P}(t)$ para algún valor de $t$ que será irrelevante en nuestra discusión.\n",
    "\n",
    "Suponga que deseamos generar un vector aleatorio cuya distribución corresponde con $\\mathbf{X}$. El muestreo de Gibbs permite obtener este resultado módulo una constante arbitraria.\n",
    "\n",
    "- El muestreo de Gibbs asume que para cualquier $i$ y valores $x_j$, $j \\neq i$, podemos generar una variable aleatoria $X$ con PMF\n",
    "$$\n",
    "P\\{ X = x \\} = P\\{ X_i = x | X_j = x_j, j \\neq i \\}.\n",
    "$$\n",
    "\n",
    "El método opera usando el algoritmo MH, con una cadena de Markov con estados $\\mathbf{x} = (x_1, \\cdots, x_n)$ pero con **una distinta definición de las probabilidades de transición**. Las probabilidades de transición se definen de la siguiente forma:\n",
    "- Dado el estado presente $\\mathbf{x}$, se escoje una coordenada $1, \\cdots, n$.\n",
    "  * La coordenada se puede escoger **de forma aleatoria o de forma secuencial.**\n",
    "- Si se escoje la coordenada $i$, se genera una variable aleatoria $X$ con PMF\n",
    "  $$\n",
    "  P\\{ X = x \\} = P\\{ X_i = x | X_j = x_j, j \\neq i \\}.\n",
    "  $$\n",
    "- En el paso anterior, llamamos a $x$ el valor que toma la variable aleatoria $X$ con el procedimiento anterior, i.e., $X = x$. La coordenada $j$, en principio, es arbitraria; sin embargo, en modelos físicos se suele escoger de **acuerdo a la localidad del problema**.\n",
    "- Entonces el estado $\\mathbf{y} = (x_1, \\cdots, x_{i-1}, x, x_{i+1}, \\cdots, x_n)$ se considera un **candidato para ser el siguiente estado**.\n",
    "- Con respecto a nuestro análisis de cadenas de Markov, debemos entender a $\\mathbf{y}$ como **la siguiente distribución de probabilidad en una cadena de Markov partiendo de la distribución $\\mathbf{x}$**.\n",
    "- Esto implica que la PMF anterior nos da la probabilidad de transición\n",
    "  $$\n",
    "  q(\\mathbf{x}, \\mathbf{y}) = \\frac{1}{n} P\\{ X_i = x | X_j = x_j, j \\neq i \\}\n",
    "  $$\n",
    "- Note el cambio de nomenclatura con respecto a la lección anterior: en este caso usamos esta notación porque es más sencillo resaltar de esta forma que el cambio de un estado a otro en la cadena de Markov corresponde a un **cambio de un valor local** de $\\mathbf{x}$. El factor $1 / n$ normaliza la probabilidad de transición. \n",
    "- Recuerde que $P(A | B) = P(AB) / P(B)$, lo cual en este caso se manifiesta de la forma\n",
    "  $$\n",
    "  \\boxed{q(\\mathbf{x}, \\mathbf{y}) = \\frac{p(\\mathbf{y})}{n P\\{ X_j = x_j\\}}}\n",
    "  $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidad de aceptación del estado $\\mathbf{y}$\n",
    "\n",
    "Recordamos que para el método MH, la probabilidad de aceptación del nuevo estado es \n",
    "$$\n",
    "\\alpha_{ij} = {\\textrm{min}}\\Bigg( \\frac{P^*_j Q_{ij}}{P^*_i Q_{ji}}, 1 \\Bigg) = {\\textrm{min}}\\Bigg( \\frac{b_j Q_{ij}}{b_i Q_{ji}}, 1 \\Bigg).\n",
    "$$\n",
    "\n",
    "En este caso, dado que $p$ corresponde a la distribución estacionaria deseada, vemos que el estado $\\mathbf{y}$ se acepta con probabilidad\n",
    "\\begin{align}\n",
    "\\alpha(\\mathbf{x}, \\mathbf{y}) &= {\\textrm{min}}\\Bigg( \\frac{p(\\mathbf{y}) q(\\mathbf{y}, \\mathbf{x})}{p(\\mathbf{x}) q(\\mathbf{x}, \\mathbf{y})}, 1 \\Bigg) \\\\\n",
    "&= {\\textrm{min}}\\Bigg( \\frac{p(\\mathbf{y}) p(\\mathbf{x})}{p(\\mathbf{x}) p(\\mathbf{y})}, 1 \\Bigg) \\\\\n",
    "&= 1.\n",
    "\\end{align}\n",
    "\n",
    "Es decir, el candidato **siempre se acepta**. Esto implica que el método de muestreo de Gibbs es superior para ciertos sistemas, particularmente para aquellos donde usar el MH con una propuesta incorrecta resuelta en una tasa de rechazo muy alta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diferencias entre el método Metropolis-Hastings estándar y el muestreo de Gibbs\n",
    "\n",
    "Podemos notar que ambos métodos son muy similares. Sin embargo,\n",
    "- **la sutil diferencia yace en que con el MH la actualización de una realización a otra ocurre a nivel del estado de forma global, mientras que con el muestreo de Gibbs la actualización ocurre localmente sobre cada elemento del estado**.\n",
    "- Adicionalmente, el muestreo de Gibbs corresponde a un caso especial de MH, en el cual la propuesta **siempre se acepta**.\n",
    "- *Where's the catch?* Para el caso del muestreo de Gibbs, **se debe conocer la distribución condicional de las variables**. Para nuestro beneficio, muchos problema en la física caen dentro de esta categoría."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Muestreo de Gibbs aplicado a un campo escalar 1-D acoplado\n",
    "\n",
    "Considere una cadena periódica de $N$ variables reales $x_1,\\dots,x_N$ (campo escalar 1-D con condiciones periódicas).  \n",
    "La energía del sistema (Hamiltoniano) es cuadrática y local:\n",
    "$$\n",
    "H(\\mathbf{x}) \\;=\\; \\frac{1}{2}\\sum_{i=1}^N (x_i - x_{i+1})^2 \\;+\\; \\frac{m^2}{2}\\sum_{i=1}^N x_i^2,\n",
    "\\qquad x_{N+1}\\equiv x_1,\n",
    "$$\n",
    "donde $m^2 \\ge 0$ corresponde a un término de masa.\n",
    "A temperatura $T$ (o temperatura inversa $\\beta = 1/T$), la distribución estacionaria debería ser una distribución de equilibrio dada por la distribución de Boltzmann:\n",
    "$$\n",
    "p(\\mathbf{x}) \\propto \\exp\\big(-\\beta H(\\mathbf{x})\\big).\n",
    "$$\n",
    "Nuestro objetivo es realizar un muestreo de Gibbs que actualiza $x_i$ según la probabilidad condicional\n",
    "$$\n",
    "p(x_i \\mid \\mathbf{x}_{\\setminus i}),\n",
    "$$\n",
    "donde $\\setminus i$ corresponde a la *diferencia en el conjunto*, i.e., los componentes de $\\mathbf{x}$ que no están presentes en $i$.\n",
    "\n",
    "De esta manera podemos simular la cadena de Markov y comparar resultados numéricos con la teoría. **Note que en este caso tenemos distribuciones de probabilidad continuas**. A pesar de esto, podemos hacer nuestro análisis en analogía con el caso discreto. Adicionalmente, en la computadora todas las distrbuciones se representan de forma discreta.\n",
    "\n",
    "#### Cálculo de la probabilidad condicional completa (Gaussianas exactas)\n",
    "\n",
    "Para este caso en particular, podemos evaluar la distribución condicional de las variables. Recuerde que este paso **es necesario para poder aplicar el muestreo de Gibbs**.\n",
    "\n",
    "La energía sólo contiene términos locales que involucran $x_i$ y sus vecinos $x_{i-1}, x_{i+1}$. Los términos que dependen de $x_i$ son:\n",
    "$$\n",
    "\\frac{1}{2}(x_i-x_{i-1})^2 + \\frac{1}{2}(x_i-x_{i+1})^2 + \\frac{m^2}{2}x_i^2.\n",
    "$$\n",
    "Podemos desarrollar esta suma y al ignorar términos que no dependen de $x_i$ obtenemos:\n",
    "$$\n",
    "H_{\\text{loc}}(x_i) = \\Big(1+\\tfrac{m^2}{2}\\Big) x_i^2 \\;-\\; x_i(x_{i-1}+x_{i+1}).\n",
    "$$\n",
    "Definamos $a \\equiv 1 + \\tfrac{m^2}{2}$ y $b \\equiv x_{i-1}+x_{i+1}$. Entonces\n",
    "$$\n",
    "H_{\\text{loc}}(x_i) = a x_i^2 - b x_i\n",
    "$$\n",
    "Este es el término de energía local. Recordemos que deseamos la **probabilidad condicional** de $x_i$ dado su complemento. \n",
    "Desde una perspectiva física, el término de energía local debe ser el único término involucrado en este cálculo. Dejando factores constantes de lado, tenemos:\n",
    "$$\n",
    "\\pi(x_i\\mid \\mathbf{x}_{\\setminus i}) \\propto \\exp\\big(-\\beta H_{\\text{loc}}(x_i)\\big)\n",
    "= \\exp\\Big(-\\beta\\big[a x_i^2 - b x_i\\big]\\Big),\n",
    "$$\n",
    "Esta es la distribución Gaussiana en $x_i$. Los indicadores de la distribución se pueden observar completando el cuadrado. Tenemos:\n",
    "$$\n",
    "a x_i^2 - b x_i = a \\Bigg( x_i^2 - \\frac{b}{a}x_i \\Bigg) = a \\Bigg[ \\Big(x_i - \\frac{b}{2a} \\Big)^2 - \\Big( \\frac{b}{2a} \\Big)^2 \\Bigg],\n",
    "$$\n",
    "de manera tal que el exponente corresponde a\n",
    "$$\n",
    "-\\beta\\big[a x_i^2 - b x_i\\big] = -\\beta a \\Big(x_i - \\frac{b}{2a} \\Big)^2 + \\beta a \\Big( \\frac{b}{2a} \\Big)^2.\n",
    "$$\n",
    "Note que el segundo término es constante con respecto a $x_i$ entonces solo afecta la normalización, la cual es irrelevante para el método de muestreo de Gibss. Entonces:\n",
    "$$\n",
    "\\boxed{\\pi(x_i\\mid \\mathbf{x}_{\\setminus i}) \\propto \\exp \\Big( -\\beta a \\Big(x_i - \\frac{b}{2a} \\Big)^2 \\Big)}.\n",
    "$$\n",
    "Con esto, sabemos que:\n",
    "- Valor de expectación condicional\n",
    "  $$\n",
    "  E[x_i | \\mathbf{x}_{\\setminus i}] = \\frac{b}{2a} = \\frac{x_{i-1}+x_{i+1}}{2 + m^2}.\n",
    "  $$\n",
    "- Varianza condicional\n",
    "  $$\n",
    "  \\text{var}[x_i | \\mathbf{x}_{\\setminus i}] = \\frac{1}{2\\beta a} = \\frac{1}{\\beta(2 + m^2)}.\n",
    "  $$\n",
    "Recordamos que necesitamos esta probabilidad condicional para evaluar el método de muestreo de Gibss.\n",
    "\n",
    "#### Muestreo de Gibbs (dos variantes)\n",
    "\n",
    "1. **Escaneo secuencial (determinista):** para $t = 0,1,\\cdots$ se recorre $i = 1 \\cdots N$ y se muestrea $x_i$ de su probabilidad condicional dada la configuración actual.\n",
    "2. **Escaneo aleatorio:** en cada paso se elige un $i$ uniformemente en $\\{1,\\cdots,N\\}$ y se actualiza $x_i$.\n",
    "\n",
    "Ambos son muestreos de Gibbs válidos. En esta lección, implementaremos el escaneo secuencial.\n",
    "\n",
    "#### Implementación\n",
    "\n",
    "Realizaremos la implementación como se detalla a continuación. Implemente una función que realizar un paso del muestreo de Gibbs para el ejemplo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbsStep(x, beta, m):\n",
    "    # x debe ser un arreglo (preferiblemente np.ndarray) que será actualizado con base\n",
    "    # al muestreo de Gibbs usando la probabilidad condicional que obtuvimos\n",
    "    # Puede utilizar np.random.normal para la distribución normal\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora definamos los parámetros del problema e invoquemos `gibbsStep` para generar una realización de la cadena de Markov una cantidad $N$ de veces. Para la condición inicial podemos considerar que $x_i = 0\\; \\forall i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSites = 64\n",
    "mVal = 1.0\n",
    "betaVal = 10.0\n",
    "nSteps = 50_000\n",
    "\n",
    "# Valor inicial\n",
    "x = np.zeros(nSites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora necesitamos una estructura de datos para guardar todas las realizaciones de la cadena de Markov que satisfacen el muestreo de Gibbs. Podemos usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.zeros((nSteps, nSites))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora aplicamos `gibbsStep` en un `for loop` una cantidad de `nSteps` veces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(nSteps):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas realizaciones de cada paso de la cadena de Markov satisfacen el muestreo de Gibbs. Corresponden a posibles valores que puede tener el campo $\\mathbf{x}$ que satisfacen nuestra condición de equilibrio. Sin embargo, la cantidad que satisface la distribución de Boltzmann es la **energía de la configuración**. Implemente una función que calcula la energía de cada configuración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy(x, m):\n",
    "    # Para esto puede ser muy útil usar np.roll\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos calcular la energía de la configuración **de cada realización de la cadena de Markov**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = np.array([energy(s, m) for s in samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y con esto realizar un histograma de la distribución de energías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(energies, bins=60, density=True, color='lightblue', alpha=0.7)\n",
    "plt.xlabel('Energía total $E(\\\\mathbf{x})$')\n",
    "plt.ylabel('Probabilidad')\n",
    "plt.title('Distribución de energías ~ Boltzmann $\\\\, e^{-\\\\beta E}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realice un gráfico como función del tiempo de algún valor $x_i$ ($i = N / 2$, por ejemplo). Observe el valor de la variable como función del tiempo. ¿Porqué se comporta de esa forma? ¿Cómo explica este comportamiento?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
